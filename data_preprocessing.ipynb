{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import DataHandler, save_encoded_data, clean_text, load_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing non-travel related data: 100%|██████████| 14439/14439 [00:00<00:00, 25663.36it/s]\n",
      "Processing travel related data: 100%|██████████| 39072/39072 [00:06<00:00, 6238.88it/s]\n"
     ]
    }
   ],
   "source": [
    "non_travel_related_data = load_json('filtered_data/non_travel_related.json')\n",
    "travel_related_data = load_json('filtered_data/travel_related.json')\n",
    "\n",
    "cleaned_texts_non_travel = []\n",
    "cleaned_texts_travel = []\n",
    "\n",
    "for data in tqdm(non_travel_related_data, desc=\"Processing non-travel related data\"):\n",
    "    text = data['content']\n",
    "    cleaned_text = clean_text(text)\n",
    "    cleaned_texts_non_travel.append(cleaned_text)\n",
    "\n",
    "for data in tqdm(travel_related_data, desc=\"Processing travel related data\"):\n",
    "    text = data['content']\n",
    "    cleaned_text = clean_text(text)\n",
    "    cleaned_texts_travel.append(cleaned_text)\n",
    "\n",
    "cleaned_texts_all = cleaned_texts_non_travel + cleaned_texts_travel\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "train_texts_non_travel, test_texts_non_travel, train_labels_non_travel, test_labels_non_travel = train_test_split(\n",
    "  cleaned_texts_non_travel, [0]*len(cleaned_texts_non_travel), test_size=test_size, random_state=42)\n",
    "\n",
    "train_texts_travel, test_texts_travel, train_labels_travel, test_labels_travel = train_test_split(\n",
    "  cleaned_texts_travel, [1]*len(cleaned_texts_travel), test_size=test_size, random_state=42)\n",
    "\n",
    "train_texts = train_texts_non_travel + train_texts_travel\n",
    "train_labels = train_labels_non_travel + train_labels_travel\n",
    "\n",
    "test_texts = test_texts_non_travel + test_texts_travel\n",
    "test_labels = test_labels_non_travel + test_labels_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_handler = DataHandler(tokenizer_name='bert-base-chinese')\n",
    "\n",
    "train_texts, train_labels = shuffle(train_texts, train_labels, random_state=42)\n",
    "test_texts, test_labels = shuffle(test_texts, test_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = data_handler.gen_encoded_data(train_texts, max_length=512)\n",
    "test_encodings = data_handler.gen_encoded_data(test_texts, max_length=512)\n",
    "all_encodings = data_handler.gen_encoded_data(cleaned_texts_all, max_length=512)\n",
    "\n",
    "save_encoded_data('encoded_data/train/encodings_512', train_encodings)\n",
    "save_encoded_data('encoded_data/train/labels', train_labels)\n",
    "save_encoded_data('encoded_data/test/encodings_512', test_encodings)\n",
    "save_encoded_data('encoded_data/test/labels', test_labels)\n",
    "save_encoded_data('encoded_data/all_512', all_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = data_handler.gen_encoded_data(train_texts, max_length=256)\n",
    "test_encodings = data_handler.gen_encoded_data(test_texts, max_length=256)\n",
    "all_encodings = data_handler.gen_encoded_data(cleaned_texts_all, max_length=256)\n",
    "\n",
    "save_encoded_data('encoded_data/train/encodings_256', train_encodings)\n",
    "# save_encoded_data('encoded_data/train/labels', train_labels)\n",
    "save_encoded_data('encoded_data/test/encodings_256', test_encodings)\n",
    "# save_encoded_data('encoded_data/test/labels', test_labels)\n",
    "# save_encoded_data('encoded_data/all', all_encodings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
